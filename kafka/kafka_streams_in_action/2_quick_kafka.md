# 2. 빠르게 살펴보는 카프라

## 데이터 문제 : 데이터 관리 솔루션의 요구사항
 * 중앙 저장소로 데이터를 신속하게 전송
 * 데이터 복제 기능으로 인한 failover
 * 많은 수의 데이터 컨슈머로 확장 가능

==> 카프카


## 카프카 아키텍쳐

### 1. 카프카는 메시지 브로커다.
 * 브로커는 상호 간 유익한 교환이나 거래를 위하 각자 반드시 알 필요가 없는 두 부분을 묶는 중개자다.
 * 카프카는 프로듀서나 컨슈머에 관한 어떤 상태도 유지 하지 않고, 메시지 교환소로만 작동한다.

### 2. 카프카는 로그다.
 * 카프카의 기본 메커니즘은 로그다.
   * 여기서 로그란? `추가만 가능한 시간순으로 완전히 정렬된 레코드 시퀀스`
 * 로그는 들어오는 레코드가 추가되는 파일이며, 각 레코드와 연관된 타임스탬프가 없더라도 시간에 따라 암묵적으로 정렬된다.
 * 카프카의 토픽은 토픽 이름으로 분리된 로그다. 
 * 토픽은 라벨이 붙은 로그라고 할 수 있다.
 * 로그가 머신 클러스터 간에 복제된 후 하나의 머신이 중지되면, 로그 파일을 재생하는 것으로 빠르게 복구할 수 있다.

### 3. 로그 동작 방식
 * 카프카 설치시 설정 중 하나는 `log.dir` 이며, 로그 데이터를 저장하는 위치다.
 * 각 토픽은 지정된 로그 디렉토리 아래의 하위 디렉토리에 매핑된다.

#### 예시 : topicA는 1개의 파티션, topicB는 3개의 파티션을 갖고 있을 때
```
/logs
  /logs/topicA_partition1
  /logs/topicB_partition1
  /logs/topicB_partition2
  /logs/topicB_partition3
```

### 4. 카프카와 파티션
 * 파티션은 성능에 필수적이며, 같은 키를 가진 데이터가 동일한 파티션에 순서대로 전송되도록 보장한다.
 * 키가 없는 경우는 라운드로빈 방식으로 파티션이 할당된다.
 * 토픽을 파티션으로 분할하면, 병렬 스트림에서 토픽에 전달되는 데이터가 분할되는데 이는 카프카 처리량의 비결이다.
 * 각 메시지에는 오프셋 번호가 있고, 파티션 간의 순서는 보장되지 않지만 각 파티션 내 메시지 순서는 보장된다.
 * 파티션의 추가 효과는 토픽의 메시지를 여러 머신에 분산해 특정 토픽의 용량이 한 서버의 사용 가능한 디스크 공간에 제한되지 않게 한다.
 * 파티션 수는 주어진 토픽에 들어오는 데이터의 양을 고려해야 한다.
   * 데이터가 많을수록 처리량을 높이기 위해 더 많은 파티션이 필요, 하지만 파티션 수를 늘리면 그만큼 TCP, 열린 파일 핸들 수가 증가하게되는 트레이드오프가 있다.

### 5. 분산 로그
 * 카프카는 하나의 머신에 모든 파티션을 할당하지 않는다. 파티션별로 여러 머신에 분산한다.
 * 또한 카프카는 데이터 중복을 제공한다. 하나의 브로커에 저장하면 클러스터의 하나 혹은 그 이상의 머신에 데이터를 복제한다.

### 6. 주키퍼
 * 카프카는 리더와 팔로워 브로커 개념이 있다.
 * 각 토픽 파티션별로 하나의 브로커를 리더로 선출하고, 나머지는 팔로워가 된다.
 * 리더의 임무는 팔로워 브로커에 토픽 파티션의 복제를 할당하는 것이다.
 * 카프카 클러스터에서 하나의 브로커를 컨트롤러로 선출한다. <- 주키퍼의 역할
   * 컨트롤러가 실패하거나 사용불가가 되면, 동일 클러스터내 브로커 집합(in-sync replica)에서 새 컨트롤러를 선출한다.
 * 주키퍼의 추가 역할
   * 클러스터 멤버십 유지 관리 - 브로커가 사용불가가 되면 멤버십에서 제외시킴
   * 토픽 트래킹 - 어떤 브로커가 어떤 토픽의 리더인지, 파티션은 몇개인지를 트래킹 및 관리한다.
   * 접근 제어 - 토픽에 읽고 쓰는 권한 관리

### 7. 컨트롤러 책임
 * 토픽의 모든 파티션에 대한 리더/팔로어 관게를 설정하는 것이 컨트롤러 브로커의 역할이다.
 * 카프카 노드가 죽거나 응답하지 않으면, 할당된 모든 파티션이 컨틀롤러 브로커에 의해 재할당된다.


### 8. 로그 삭제 (`cleanup.policy=delete`)
 * 로그 삭제는 2단계로 나뉜다.
    1) 로그 세그먼트화 : 로그를 세그먼트로 나누고
    2) 세그먼트 삭제 : 오래된 세그먼트부터 순서대로 삭제
 * 세그먼트 분할 기준은 메시지 타임스탬프이며, `log.roll.ms` (없다면, `log.roll.hours` 디폴트 168시간) 값을 통해 결정한다.
    * 용량 기준 혹은 시간 기준에 도달하면, 해당 파일을 닫고 새로운 파일에 쓰기를 시작. 이 파일을 액티브 세그먼트라고 한다.
 * 세그먼트 삭제 또한 메시지 타임스탬프 기준이며, `log.retention.ms` (없다면 > minutes > hours 순서)
    * `log.retention.bytes` : 파티션 로그 최대 크기 제어. 이 사이즈 넘어서면 이전 로그 삭제 (default: -1; 제한없음)
 * 이 기준들은 모두 파티션 당 기준이다. 그러니 파티션 수를 생각해서 계산할 것.


### 9. 로그 압축 (`cleanup.policy=compact`)
 * 키를 가진 데이터가 있고, 동일한 키를 가진 새 레코드가 이전 값을 업데이트하고 있을때를 고려해보자.
   * 이때 갑자기 크래시가 발생하거나 다시 시작된다면, 해당 키에 대한 최신 데이터로 백업할 수 있어야 한다.
 * 로그 압축을 사용하면, 키별로 가장 최신 레코드는 남기고 이전 레코드들은 삭제한다.
 * 이 방식은 주어진 키에 대한 마지막 레코드가 로그에 있음을 보장한다.


## 카프카 프로듀서
