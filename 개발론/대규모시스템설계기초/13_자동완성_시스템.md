# 13장 검색어 자동완성 시스템

## 1 문제 이해 및 설계 범위 확정

- 자동완성: 사용자가 입력하는 단어로 시작하는 단어
- 자동완성 검색어 5개
- 질의 빈도에 따른 인기 순
- 맞춤법 검사, 자동수정 없음
- 영어 소문자
- DAU 천만 명

### 요구사항

- 빠른 응답 속도
    - 페이스북 검색어 자동완성 시스템: 100ms 이내
- 연관성
- 정렬
    - 인기도 등 순쉬 모델에 의해 정렬
- 규모 확장성
- 고가용성

### 개략적 규모 추정

- DAU 천만 명, 한 사람 당 매일 10건 검색 가정
- 질의 시 평균 20바이트 입력 가정
- 글자 입력 마다 요청 전송: 평균 20회

> 대략 24,000 QPS
> 

> 최대 48,000
> 
- 20% 정도는 신규 검색이라고 가정
    - 0.4GB 신규 데이터가 매일 추가된다.

## 2 개략적 설계안 제시 및 동의 구하기

시스템을 두 부분으로 구분

1. 데이터 수집 서비스 data gathering service
    - 입력한 질의를 실시간으로 수집
    - 데이터가 많은 앱에 실시간은 바람직 하지 않으므로 추후 수정
2. 질의 서비스 query service
    - 5개의 인기검색어를 정렬해 제시

### 데이터 수집 서비스

질의문과 사용빈도를 저장하는 빈도 테이블 가정 

| 질의 | 빈도 |
| --- | --- |
| query | frequency |

### 질의 서비스

위의 빈도 테이블에서 frequency 값에 따라 계산

```sql
SELECT * FROM frequency_table
WHERE query Like `prefix%`
ORDER BY frequency DESC
LIMIT 5
```

→ 데이터가 (아주) 많아지면 병목이 될 수 있음

## 3 상세 설계

컴포넌트 상세 설계 및 최적화

- 트라이(trie) 자료구조
- 데이터 수집 서비스
- 질의 서비스
- 규모 확장이 가능한 저장소
- 트라이 연산

### 트라이 자료 구조

- 트라이(trie or prefix tree) → 시스템의 핵심 부분
    - https://medium.com/@prefixyteam/how-we-built-prefixy-a-scalable-prefix-search-service-for-powering-autocomplete-c20f98e2eff1
    - https://people.eecs.berkeley.edu/~sylvia/papers/pht.pdf
- retrieval : 문자열을 꺼내는 연산에 초점

핵심 아이디어

- 트리 형태의 자료구조
- 루트 노드는 빈 문자열
- 각 노드는 글자 하나를 저장, 26개의 자식을 가질 수 있다.
- 각 트리 노드는 하나의 단어나 접두어 문자열(prefix string)을 나타낸다.

트리

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac122fbb-6382-4320-bf37-68e21a66352e/88a5ae34-8479-4a7a-97c1-071297c4e231/Untitled.png)

용어정리

- p: 접두어의 길이
- n: 트리안에 있는 노드 개수
- c: 주어진 노드의 자식 노드 개수

가장 많이 사용된 질의어 k개를 찾으려면,

- 해당 접두어를 표현하는 노드를 찾는다. O(p)
- 해당 노드부터 시작하는 하위 트리를 탐색해 유호 노드를 찾는다.
    - 유효 노드: 유효한 검색 문자열 구성
    - O(c)
- 유효 노드를 정렬해 인기 검색어 k를 찾는다. O(clogc)

이 알고리즘의 시간 복잡도: O(p) + O(c) + O(clogc)

→ 최악의 경우 k개의 결과를 얻기 위해 전체 트라이를 다 검색해야 할 수 있다.

이를 해결하기 위해,

1. 접두어 최대 길이 제한
    - p값을 작은 정숫값으로 제한 → 접두어 노드를 찾는 단계의 시간복잡도가 줄어든다. O(p) → O(1)
2. 각 노드의 인기 검색어 캐시
    - 각 노드에 인기 검색어 다섯개 저장 (저장 공간이 많이 필요할 수 있음)
    - 최고 인기 검색어 5개를 찾는 질의의 시간 복잡도: O(c) + O(clogc) → O(1)

### 데이터 수집 서비스

실시간으로 데이터를 수정할 경우

- 매일 수천만 건의 질의 시마다 트라이가 갱신된다.
- 한 번 트라이가 만들어지면, 인기 검색어가 자주 바뀌지 않을 것이다.

데이터가 어디서 오고 어떻게 이용되는지 살펴야 한다.

→ 보통 데이터 분석 서비스 / 로깅 서비스

### 데이터 분석 서비스의 설계안


> **데이터 분석 서비스 로그**
> 

검색창에 입력된 질의에 대한 원본 데이터 보관

query와 time 정도

> **로그  취합 서버**
> 

위에서 수집한 로그를 소비하기 쉽게 취합aggregation

→ 서비스의 용례에 따라 취합 방식/주기 등은 달라질 수 있음. 데이터 취합의 실시간성 확인

> **취합된 데이터**
> 

1주일 단위로 취합

| query | time | frequency |
| --- | --- | --- |
|  | 해당 주가 시작된 날짜 | 해당 주에 질의된 횟수의 합 |

> **트라이 캐시**
> 
- 분산 캐시 시스템
- 트라이 데이터를 메모리에 유지해 읽기 성능 향상
- 매주 스냅샷 갱신

> **트라이 데이터베이스**
> 

지속성 저장소

1. 문서 저장소
    - 새 트라이를 매주 생성하므로 주기적으로 직렬화 해 저장 가능
2. 키-값 저장소
    - 해시 테이블 형태로 변환
        - 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
        - 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환

### **질의 서비스**

1. 검색 질의가 로드밸런서로 전송
2. 로드밸런서는 해당 질의를 API 서버로 전송
3. API 서버는 트라이 캐시에서 데이터러를 가져와 자동완성 검색어 제안 응답 구성
4. 캐시가 없는 경우 데이터 베이스에서 가져와 캐시 추가

> 최적화 방안
> 
- ajax 요청
- 브라우저 캐싱
    - ex. 구글) 제안된 검색어를 한 시간 캐싱
- 데이터 샘플링
    - N개의 요청 중 1개만 로깅

### 트라이 연산

> 트라이 생성
> 
- 작업 서버가 담당
- 데이터 분석 서비스 로그 / 데이터베이스로부터 취합된 데이터 이용

> 트라이 갱신
> 
1. 매주 한 번 갱신
2. 트라이의 각 노드를 개별적으로 갱신
    - 모든 상위 노드의 이용 빈도 값을 갱신해야 함

> 검색어 삭제
> 
- API 서버와 캐시 사이에 필터 계층을 사용
- 추후 업데이트 사이클 시, 데이터베이스에서 물리적 삭제

### 저장소 규모 확장

트라이가 한 서버에 넣기 너무 큰 경우에도 대응해야 한다.

- 영어만 지원하므로 첫 글자를 기준으로 샤딩 → 간단하지만 글자별 단어수의 차이가 큼
- 과거 질의 데이터 패턴을 기준으로 샤딩 → 샤드 관리자를 통해 관리

## 4 마무리

- 다국어 지원? 트라이에 유니코드 데이터를 저장
- 국가별 인기 검색어 순위가 다르다면? 국가별 다른 트라이 사용, 트라이를 CDN에 저장해 응답속도 향상
- 실시간 추이를 반영?
    - 샤딩을 통해 작업 대상 데이터 양을 줄인다.
    - 순위 모델을 바꿔 최근 검색어에 높은 가중치를 부여
    - 데이터 스트림 프로세싱 고려
        - 하둡 맵리듀스, 아파치 스파크 스트리밍, 아파치 스톰, 아파치 카프카 …
