# 14장 유튜브 설계

## 1단계 - 문제 이해 및 설계 범위 확정
 * DAU : 5백만
 * 사용자 1인당 평균 5개 비디오 시청
 * 10% 사용자가 하루 1개 비디오 업로드
 * 비디오 평균 크기 300MB
 * 비디오 저장을 위해 매일 새로 요구되는 저장 용량 = 5백만 * 10% * 300MB = 150TB
 * CDN 비용
   * 트래픽에 따라 다르며, 미국의 경우 1GB 당 0.02$
   * 매일 발생 요금은 5백만 * 5 비디오 * 0.3G * 0.02$ = 150,000$


## 2단계 - 개략적 설계안 제시 및 동의 구하기
 * CDN, BLOB 스토리지의 경우 기존 클라우드 서비스를 활용
   * 그 이유는 모든 것을 밑바닥부터 만드는 것이 시스템 설계 면접에서 중요하지 않기 때문.
  
### 비디오 업로드 절차
#### 주요 컴포넌트
 * 로드밸런서 : API 서버 각각으로 고르게 요청 분산
 * api 서버 : 비디오 스트리밍 제외한 다른 모든 요청 처리
 * metadata db : 비디오의 메타데이터 보관
 * metadata cache : 비디오 메타데이터와 사용자 객체는 캐시
 * 원본 저장소 : 원봉 비디오를 보관할 대형 이진 파일 저장소(BLOB)
 * 트랜스코딩 서버 : 비디오의 포맷을 변환하는 절차. 단말이나 대역폭 요구사항에 맞는 최적의 비디오 스트림을 제공하기 위해 필요
 * 트랜스코딩 비디오 저장소 : 트랜스코딩이 완료된 비디오를 저장하는 BLOB 저장소
 * CDN : 비디오를 캐시하는 역할

### 주요 프로세스
 * 비디오 업로드와 비디오 메타데이터 갱신을 병렬적으로 수행된다.

![image](https://github.com/jaehleeee/study-docs/assets/48814463/80bfd18e-839c-49b4-970f-b487267963c3)


### 비디오 스트리밍 절차
#### 스트리밍 프로토콜
 * MPEG-DASH : Moving Picture Experts Group Dynamic Adaptive Streaming over HTTP 의 약어
 * 애플의 HLS : HTTP Live Streaming
 * MS 스무드 스트리밍
 * 어도비 HTTP 동적 스트리밍

#### DASH와 HLS 차이 (from. Cloudflare)
 * 인코딩 형식: MPEG-DASH에서는 어떠한 인코딩 표준도 사용할 수 있지만, HLS는 H.264 또는 H.265를 사용해야 합니다.
 * 장치 지원: HLS는 Apple 장치에서 지원하는 유일한 형식입니다. iPhone, MacBook 등 Apple 제품은 MPEG-DASH로 전송되는 비디오를 재생하지 못합니다.
 * 세그먼트 길이: 2016년 이전에는 HLS의 기본 세그먼트 길이가 10초로서 두 프로토콜 간의 큰 차이 요인이었습니다. 현재는 HLS의 기본 길이가 6초이지만, 기본값에서 조정할 수 있습니다. MPEG-DASH 세그먼트는 통상적으로 길이가 2-10초이지만, 최적 길이는 2-4초입니다.
 * 표준화: MPEG-DASH는 국제 표준입니다. HLS는 Apple에 의해 개발되었으며 광범위한 지원을 받고 있지만 국제 표준으로 게시되지는 않았습니다.

## 3단계 - 상세 설계
### 비디오 트랜스코딩
 * 비디오를 녹화하면 단말(휴대폰이나 카메라)은 해당 비디오를 특정 포맷으로 저장한다.
 * 이 비디오가 다른 단말에서도 호환되려면 비트레이트와 포맷으로 저장되어야 한다.
 * 비디오 트랜스코딩이 중요한 이유
   * 가공되지 않은 원본 비디오는 저장공간을 많이 차지 한다.
   * 상당수의 단말과 브라우저는 특정 종류의 비디오 포맷만 지원한다.
     * 호환성 이슈를 위해 여러 포맷으로 인코딩 해두면 좋다.
   * 시청자에게 끊김없이 비디오 재생을 보장하려면 저화질, 고화질 비디오 모두 필요
     * 특히 모바일 단말은 비디오 화질을 자동으로 변경하거나 수동으로 변경할 수 있는게 좋다.
* 인코딩 포맷은 크게 2부분으로 구성
  * 컨테이너 : 비디오 파일, 오디오, 메타 데이터를 담는 바구니. avi, mov, mp4 같은 확장자
  * 코덱 : 비디오 화질은 ㅗ장하면 크기를 줄일 목적의 압축 및 해제 알고리즘. H.264, VP9, HEVC 가 있다.

### 유향 비순환 그래프 (DAG) 모델
 * 콘텐츠 창작자는 각자 자기만의 비디오 프로세싱 요구사항을 갖고 있다.
 * 누군가는 워터마크 표시, 썸네일 제작, 고화질 등
 * 이처럼 각기 다른 비디오 프로세싱 파이프라인을 지원하는 한편 처리 과정의 병렬성을 높이기 위해 적절한 수준의 추상화를 도입하여 클라이언트 프로그래머로 하여금 실행할 작업을 손수 정의할 수 있도록 해야한다.
 * 예를 들어 페이스북의 스트리밍 비디오 엔진은 DAG(Directed Acyclic Graph) 프로그래밍 모델을 도입, 작업을 단계별로 배열할 수 이쏟록 했다.

![image](https://github.com/jaehleeee/study-docs/assets/48814463/5e09a9f8-27e1-4f5e-8832-7a5ca3622b9f)

 * 검사 : 비디오에 손상없는지 검사
 * 비디오 인코딩 : 비디오를 다양한 해상도, 코덱, 비트레이트 조합으로 인코딩
 * 섬네일 : 사용자 업로드 이미지나 비디오에서 자동 추출
 * 워터마크

### 비디오 트랜스코딩 아키텍처

![image](https://github.com/jaehleeee/study-docs/assets/48814463/be6ced14-4698-49c9-9db3-8368d88a9bc1)


#### 전처리기
 * 비디오 분할 : 비디오를 GOP 단위로 쪼갠다. GOP(Group of pictures) 독릭재생 가능한 프레임 그룹
 * DAG 생성 : 클라이언트 프로그래머가 작성한 설정 파일을 기반으로 dag 생성
 * 데이터 캐시 : gop와 메타데이터를 임시 저장소에 보관, 인코딩 실패시 보관된 데이터를 활용해 인코딩을 재개한다.
#### DAG 스케쥴러
 * DAG 그래프를 몇개 단계로 분한한 다음 각각 자원 관리자의 작업 큐에 넣는다.₩
#### 자원관리자
 * 3개의 큐와 작업 스케쥴러로 구성
 * 작업 큐 : 실행할 작업이 보관
 * 작업 서버 큐 : 작업 서버의 가용상태 정보 보관
 * 실행 큐 : 현재 실행 중인 작업 및 작업 서버 정보가 보관
 * 작업 스케쥴러 : 최적의 작업과 서버 조합을 골라 해당 작업 서버가 작업 수행하도록 지시.
#### 작업실행서버
 * DAG에 정의된 작업을 수행
#### 임시저장소
 * 저장할 데이터 유형, 크기, 이용 빈도에 따라 다양한 저장소 시스템 활용 가능.
 * 메타데이터는 메모리 캐시
 * 비디오, 오디오는 BLOB 저장소
 * 임시저장소의 데이터는 비디오 프로세싱이 완료되면 삭제한다.
#### 인코딩된 비디오
 * 최종 결과물

### 시스템 최적화
 * 속도, 안정성, 비용 측면에서의 최적화

#### 속도
 * 업로드 센터를 사용자 근거리에 지정하여 업로드 속도 개선
 * 느슨하게 결합된 시스템을 만들어서 병렬성 높이는 것
#### 안정성
 * 허가된 사용자만 업로드할 수 있도록 미리 사인된 업로드 url 이용
 * 비디오 보호
   * DRM : 애플의 페어플레이, 구글의 와이드바인, MS의 플레이레디
   * AES : 비디오를 암호화하고 접근 권한을 설정하는 방식. 재생시 복호화됨.
   * 워터마크 
#### 비용
 * 인기 비디오는 cdn, 다른 비디오는 비디오 서버를 통해 재생
 * 인기가 별로 없는 비디오는 인코딩할 필요 없을 수도 있다.
 * 특정 지역에서만 인기있다면 다른 지역으 옮기지 않는다.
 * CDN 직접 구축

### 오류처리
 * 회복 가능 오류와 회복 불가능 오류를 구분하여 처리

## 4단계 - 마무리
### 더 얘기해볼 주제
 * API 계층 규모 확장성 확보
 * 데이터베이스 규모 확장성 확보
 * 라이브 스트리밍
 * 비디오 삭제





