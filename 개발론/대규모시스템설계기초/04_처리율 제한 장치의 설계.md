# 처리율 제한 장치의 설계
 * 네트워크 시스템에서 처리율 제한 장치(rate limiter)는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장ㅇ치다.
 * 예시
   * 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
   * 같은 IP 주소로는 하루 10개 이상 계정을 생성할 수 없다.

### 처리율 제한 장치를 두면 좋은 점
 * DoS 공경에 의 한 자원 고갈 방지
 * 비용 절감
   * 서버를 많이 두지 않아도 된다.
   * third-party API 사용료를 지불하면 특히 더
 * 서버 과부하 막는다.

### 처리율 제한 장치 구현하는 4단계
 1. 문제 이해 및 설계 범위 확정
 2. 개략적 설계안 제시 및 동의 구하기
 3. 상세 설계
 4. 마무리

## 1. 문제 이해 및 설계 범위 확정
 * 면접관과 소통하면서 어떤 제한 장치를 구현해야 하는지 구체화하기
#### 요구사항
 * 낮은 응답시간 유지
 * 가능한 적은 메모리 사용
 * 분산형 처리율 제한 (하나의 장치로 여러 서버나 프로세스 공유)
 * 예외 처리 : 요청이 제한되었을때 사용자에게 이를 분명히 안내해야 한다.
 * fault tolerance : 이 장치가 전체 시스템에 영향 주면 안된다.

## 2. 개략적 설계안 제시 및 동의 구하기
### 장치를 어디에 둘 것인가?
 * 클라이언트 측 : 비추.. 쉽게 위변조 가능하며 모든 클라이언트의 구현 통제의 여러움
 * 서버 측 : 서버에 두거나, 서버 앞단에 미들웨어를 둔다.
   * 미들웨어에서 요청이 막히면 429(Too many requests) 응답을 준다.
   * 보통 미들웨어는 API 게이트웨이 라는 컴포넌트에 의해 구현된다.
#### API 게이트웨이
 * 처리율 제한
 * SSL 종단
 * 사용자 인증
 * IP 허용 목록 관리 등

(livecloud 에서도 pasta APIGW 사용중, 왜 쓰는지는 잘 모르겠음.)

#### 처리율 장치를 결정할때 판단 요소
 * 기술 스택
 * 처리율 제한 알고리즘 - third-party 사용하기로 했다면 선택지 제한될 수 있음
 * 이미 다른 이유로 API gateway 쓰기로 했다면, 처리율 제한 기능도 포함시켜야 할 수 있다.
 * 인력 비용

### 처리율 제한 알고리즘

### 토큰 버킷 알고리즘
 * 시스템이 일정 시간내에 처리할 양을 고정
<img src="https://github.com/jaehleeee/study-docs/assets/48814463/6fdbe5f5-c7ba-468e-8085-566dcfc066a1" width="500"/>

#### 인자
 * 버킷 크기
 * 토큰 공급률
#### 원리
 * 토큰을 담은 용량이 정해진 버킷이 있따.
 * 토큰 공급기가 일정 시간, 매초 혹은 매분 마다 일정 수의 토큰을 주기적으로 채운다 (refill rate)
   * 이때 이미 버킷이 꽉 찼다면 남은 토큰은 버려진다
 * 각 요청은 처리될때마다 토큰을 하나 사용한다.
   * 토큰이 충분하면 버킷에서 토큰을 하나 꺼낸 후 요청을 시스템에 전달한다.
   * 토큰이 부족하면, 요청은 버려진다.
#### 장점
 * 구현 쉽다
 * 메모리 적게 사용
 * 짧은 시간 집중 트래픽 처리 가능
#### 단점
 * 버킷 크기와 토큰 공급률 튜닝이 쉽지 않다.

### 누출 버킷 알고리즘
 * 시스템의 처리 속도를 고정
<img src="https://github.com/jaehleeee/study-docs/assets/48814463/a583e2c4-bef2-4f1a-913f-cbf20cccacd4" width="500"/>

#### 인자
 * 버킷 크기
 * 처리율
#### 원리
 * 특징
   * 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다는 점이 다르다.
   * FIFO 큐로 구현된다.
 * 요청이 오면 큐가 가득찼는지 체크
 * 빈자리가 있으면 큐에 요청 추가
 * 큐가 가득 차 있으면 요청은 버려진다.
 * 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.
#### 장점
 * 메모리 사용 효율적
 * 시스템 안정적
#### 단점
 * 단시간에 요청이 몰리면 최신 요청들은 버려진다.
 * 인자 튜닝이 까다롭다.

### 고정 윈도 카운터 알고리즘
 * 토큰 버킷 알고리즘과 비슷함. 버킷 크기와 토큰 공급률이 동일하다면 공정 윈도 카운터가 됨.

#### 인자
 * 초당 요청 허용할 임계치
#### 원리
 * 타임라인을 고정된 간격의 우니도로 나누고, 각 윈도마다 카운터를 붙인다
 * 요청이 오면 이 카운터 값이 증가하고
 * 카운터 값이 사전 설정된 임계치에 도달하면 새로운 요청은 버려진다
#### 장점
 * 메모리 효율 좋다
 * 이해 쉽다
 * 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴 처리에 좋다.
#### 단점
 * 단시간 트래픽이 집중될 경우, 윈도에 할당된 양보다 더 많은 요청이 처리될 수 있다.

### 이동 윈도 로그 알고리즘
 * 고정 윈도 카운터의 단점을 해결
<img src="https://github.com/jaehleeee/study-docs/assets/48814463/416f7d93-f92c-481f-bb01-fc33889c8a18" width="500"/>

#### 인자
 * 분당 최대 요청 처리 가능 수
#### 원리
 * 고정 윈도 카운터와 비슷하지만,
 * 고정 윈도는 고정된 타임라인 윈도를 사용하지만 (13:01 / 13:02 / ..)
 * 해당 요청일정 시간을 윈도로 계산한다.
 * 이동 윈도는 요청이 들어온 시점을 로깅해놓고, 로깅된 수를 체크한다
 * 로깅된 수가 임계치 이상이면 요청을 거절한다
 * 만료 시간이 지난 로그는 삭제한다
#### 장점
 * 고정 윈도 단점 해결
#### 단점
 * 요청 시간을 모두 저장해야 하므로 메모리를 많이 사용
   * (마지막꺼만 보관하면 되지 않나?)


### 이동 윈도 카운터 알고리즘
<img src="https://github.com/jaehleeee/study-docs/assets/48814463/5247c2d5-7c2d-4d0c-9ce7-57fca19aedc4" width="500"/>

#### 인자
 * 분당 최대 처리 임계치 수
#### 원리
 * 위에 두 윈도 알고리즘을 결합.
 * 현재 1분간 요청 수와 직전 1분간 요청 수를 기록
 * 현재 시점이 현재 1분에서 어느 정도 지난 시점인지 보고(예를 들면 30%), 남은 시간만큼 직전 1분간 요청 수의 처리중인 수를 결정 (70%)
 * 현재 시점을 기준으로 최근 1분간 요청이 들어온 개수를 계산히여 이를 임계치 기준에서 허용/거절 인지 판단
#### 장점
 * 짧은 시간 트래픽이 대응
 * 메모리 효율이 좋다
#### 단점
 * 직전 시간대에 도착한 요청이 균등하게 분포한다는 가정이 들어가서 느슨하다.
   * 그러나 클라우드플레어 실험 결과 시스템 실제 상황과 맞지 않는 경우는 0.003%에 불과하다

### 카운터의 저장
 * DB는 느리다.
 * 그래서 보통 메모리 상 동작 캐시가 좋다 (만료 정책도 지원하므로)
 * REDIS 자주 사용한다, 2개 명령어 지원되서 좋음
   * INCR : 카운터 값 증가
   * EXPIRE  : 카운터에 타임아웃 설정

## 3. 상세 설계
<img src="https://github.com/jaehleeee/study-docs/assets/48814463/2f865918-9eba-4706-ac45-d953bde55a15" width="500"/>

 * 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가.
    * 설정 파일 형태로 디스크 저장해둘 수 있다. 
 * 처리가 제한된 요청들은 어떻게 처리되는가.
   * 나중에 처리하기 위해 큐에 보관 가능
#### 처리율 제한시 사용되는 HTTP 헤더
 * X-Ratelimit-Remaining : 윈도에 남은 처리 가능 요청 수
 * X-Ratelimit-Limit : 매 윈도마다 전송 가능 요청 수 
 * X-Ratelimit-Retry-After : 제한 걸리지 않으려면 몇 초 뒤에 요청 다시 보내야하는지 알림.

### 분산 환경에서 처리율 장치 2가지 이슈 : 경쟁 조건과 동기화
#### 경쟁조건
 * 락이 가장 쉬운 해결 요소, 하지만 성능 떨어뜨린다
 * 락 대신 쓸 수 있는 2가지 해결책 : 루아 스크립트, 정렬 집합 불리는 레디스 자료구조

#### 동기화 문제 해결방안 2가지
 * 고정 세션 활용하여 같은 클라이언트의 요청은 같은 처리율 제한 장치로 보낼 것
 * 레디스와 같은 중앙 집중형 데이터 저장소 쓰기

### 그 밖의
#### 성능 최적화 : 엣지 서버 사용
#### 모니터링 요소 : 알고리즘이 효과적인가

## 4. 마무리 : 도움될 요소
 * 경성 또는 연성 처리율 제한
    * 연성 : 잠시동안은 임계치 넘는 것을 허용한다. 
 * 다양한 계층에서 처리율 제한 (OSI 7 layer)
 * 클라이언트에서 처리율 제한을 회피하려면
   * 앞단 캐시를 통해 API 호출 줄인다
   * 짧은 시간동안 너무 많이 요청하지 않기
   * 예외 상황 우아하게 복구하기
   * 재시도시 충분한 백오프 시간 두기

