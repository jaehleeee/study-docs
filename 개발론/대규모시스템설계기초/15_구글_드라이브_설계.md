# 15장 구글 드라이브 설계

## 1단계 문제 이해 및 설계 범위 확정
## 대략적 요구사항
- 파일 업로드/다운로드, 파일 동기화, 알림이 중요 기능
- 모바일 앱 / 웹 앱 둘 다 지원이 필요
- 파일 암호화 필요
- 파일 크기의 10GB 제한
- DAU 천만(10Million)

#### 이번 장에서는 다음 기능의 설계에 집중
- 파일 추가.
- 파일 다운로드
- 여러 단말에 파일 동기화
- 파일 갱신 이력 조회
- 파일 공유
- 파일이 편집되거나 삭제되거나 새롭게 공유되었을 때 알림 표시

#### 다음 기능은 논의 하지 않음
- 구글 문서 편집 및 협업 기능. 동시 편집 설계 범위에서 제외

### 비 기능적 요구사항
- 안정성
- 빠른 동기화 속도
- 네트워크 대역폭 - 불필요한 데이터 사용 X, 특히 모바일에서는 더욱 더 중요
- 규모 확장성
- 높은 가용성

### 개략적 추정치

- 가입 사용자 오천만(50Million), 천만 명의 DAU
- 모든 사용자에게 10GB의 무료 저장공간
- 매일 각 사용자가 평균 2개의 파일을 업로드, 파일 평균 크기는 500KB
- 읽기 : 쓰기 비율은 1:1
- 필요한 저장공간 총량 = 5천만 사용자 x 10GB  = 500PB
- 업로드 API QPS = 1천만 사용자 x 2회 업로드 / 24시간 / 3600초 = 약 240
- 최대 QPS = QPS x 2 = 480

## 2단계 개략적 설계안 제시 및 동의 구하기
모든 것을 담은 1대 서버에서 출발해 점진적으로 천만 사용자 지원이 가능한 시스템으로 발전시켜 봄
우선 다음과 같은 구성의 서버 한 대로 시작

- 파일을 올리고 다운로드 하는 과정을 처리할 웹 서버
- 사용자 데이터, 로그인 정보, 파일 정보 등의 메타데이터를 보관할 데이터베이스
- 파일을 저장할 저장소 시스템. 파일 저장을 위해 1TB의 공간을 사용할 것

이와 같은 구성을 위해,

- 아파치 웹 서버 설치
- MySQL 설치
- 파일을 저장할 drive/ 라는 디렉터리를 준비
    - 하위에 유저별 하위 디렉터리
    - 파일명은 원래 파일과 같은 이름으로 둔다

### API
기본적으로 3가지 API 필요

- 파일 업로드
- 다운로드
- 갱신 히스토리 제공

#### 파일 업로드 API

두 가지 종류의 업로드를 지원

- 단순 업로드 : 파일 크기가 작을 때 사용
- 이어 올리기 : 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 가능성이 높다고 생각되면 사용


#### 한 대 서버의 제약 극복
- 가장 먼저 떠오르는 해결책은 데이터의 *샤딩*
- 데이터의 안정성을 보장할 수 있는가
- S3 활용

#### 추가 연구해볼 사항
- 로드밸런서 + 웹서버를 통한 부하분산
- 메타데이터 데이터베이스 : DB를 분리하여 SPOF를 회피. 다중화/샤딩 등을 통해 가용성과 규모 확장 요구사항 대응

### 동기화 충돌
 * 먼저 처리되는 변경은 성공, 나중에 처리되는 변경은 충돌이 발생한 것으로 표시
 * 여기서는 충돌이 발생한 파일을 버린다. 하지만, 이걸 처리하는 방법들은 다양하게 있다

### 개략적 설계안
- 클라우드 저장소 - S3
- 아카이빙 저장소(cold storage)는 오래된 파일을 저장하는 시스템으로 분리되어있고
- 블록 저장소 서버 - 파일 블록을 클라우드 저장소에 업로드하는 서버.

## 3단계 상세 설계

### 블록 저장소 서버

정기적으로 갱신되는 큰 파일들을 전체 파일을 서버로 보내기보단, 최적화가 필요. 방법은 크게 2가지

- 델타 동기화 : 파일이 수정되면 전체 파일 대신 수정이 일어난 블록만 동기화
- 압축 : 블록 단위로 압축해 두면 데이터 크기를 많이 줄일 수 있음.
    - 텍스트 파일은 gzip, bzip2 / 이미지나 비디오는 별도 압축

<aside>
💡 이 시스템에서 블록 저장서 서버는 파일 업로드에 관계된 힘든 일을 처리하는 컴포넌트. 
* 파일을 블록으로 쪼개고
* 압축 알고리즘 적용하고 (블록마다)
* 암호화까지
* 전체 파일 저장소로 보내지않고, 수정된 블록만 전송

</aside>

- 새 파일이 추가되었을 때, 블록 저장소 서버의 동작은 위와 같음

이러한 델타 동기화 전략/압축 을 통해 네트워크 대역폭 사용량을 절감할 수 있음

### 높은 일관성 요구사항

이 시스템은 강한 일관성 모델을 기본으로 지원 (C)

같은 파일이 사용자에 따라 다르게 보이는 것을 허용할 수 없음

<aside>
💡 메모리 캐시는 보통 최종 일관성 모델을 지원하기때문에, 다음 사항을 보장해야 한다.
* 캐시에 보관된 사본과 DB의 원본이 일치해야 한다
* 원본에 변경이 발생하면 사본을 무효화 한다.

</aside>

- RDBMS는 ACID를 보장해 강한 일관성을 보장하기 쉬움
- NoSQL은 동기화 로직 안에 프로그램 해 넣어야 한다.

여기서는 RDBMS를 채택하여 높은 일관성 요구사항에 대응

### 메타데이터 데이터베이스

대략적인 스키마는 위와 같습니다. 

## 업로드 절차

사용자가 파일을 업로드하면 벌어지는 일은 다음과 같다. 

### 다운로드 절차

파일이 새로 추가되거나 편집되면 자동으로 다운로드가 되어야한다. 

- 알림으로 알거나 (Online)
- 접속시에 가져가게 된다


### 알림 서비스

알림 서비스의 경우, 

- 롱 폴링
- 웹소켓

의 2가지가 있는데, 여기서는 롱 폴링을 사용한다.

<aside>
💡 채팅과 달리, 양방향 통신이 필요하지않음.
알림이 그렇게 자주 발생하지않고, 단시간에 많은 양의 데이터를 보낼 일은 없음

</aside>

### 저장소 공간 절약

- 해시 값을 비교해서 중복 블록을 제거하거나
- 한도를 설정, 중요한 버전만 보관하거나
- 자주 쓰이지 않는 데이터는 cold storage에 저장하거나

### 장애 처리

대부분 다중화로 해결이 가능

알림 서비스의 경우, 롱폴링 백만개를 유지하는건 가능하지만, 백만개를 동시 재연결하는건 불가능

- 복구가 느릴 수 밖에 없다.

## 4단계 마무리

설계에 정답은 없다.

예를 들어.. 블록 저장서 서버 없으면? → 더 빠르다. 하지만, 분할/압축/암호화 로직을 클라이언트에 두어야 하므로 플랫폼별 구현이 달라진다.
