# 9장 S3와 유사한 객체 저장소

## 저장소 시스템 101

- 블록 저장소
    - HDD, SSD같은 물리 드라이버가 대표적인 예
    - 가장 유연하게 사용할 수 있는 저장소
    - 데이터베이스에서 원시블록을 직접 제어하여 최대한의 성능을 이끌어내는 방식으로 사용
- 파일 저장소
    - 한단계 더 추상화된 저장소로, 블록 저장소 위에 구현됨
    - 디렉터리 구조를 사용
    - 가장 범용적인 저장소
- 객체 저장소
    - 데이터 영속성이 높고, 대규모 애플리케이션을 지원할 수 있으며, 비용이 낮음. 하지만 성능은 느림
    - cold 데이터에 특화됨
    - 모든 데이터를 수평적 구조로 저장
    - RESTful API를 통해 데이터에 접근 가능
    - 사내 플랫폼으로는 Nubes

# 1단계: 문제 이해 및 설계 범위 확정

## 기능 요구사항

- 버킷 생성
- 객체 업로드 및 다운로드
- 객체 버전
- 버킷 내 목록 출력 기능 (aws s3 ls 명령어와 유사하게)

## 비기능 요구사항

- 데이터 크기
    - 큰 객체(수 GB 이상)와 작은 객체(수 KB 정도)를 효율적으로 저장해야 함
    - 매년 100PB 추가 저장 가능해야 함
- 신뢰성
    - 99.9999%의 데이터 내구성
    - 99.99%의 서비스 가용성

## 대략적인 규모 추정

- 가정
    - 저장할 객체 크기의 유형별 분포
        - 20%는 1MB 미만의 작은 객체
        - 60%는 1MB ~ 64MB 크기의 중간 객체
        - 20%는 64MB 이상의 큰 객체
    - IOPS
        - 하드 디스크 1개가 초당 100~150회의 데이터 탐색을 지원
    - 모든 객체의 메타데이터 크기가 약 1KB
- 객체 유형별 중앙값을 사용해서 계산해보면, 40%의 저장 공간 사용률을 유지하는 경우 수용 가능한 객체 수는 6억 8천만개
    
![image](https://github.com/user-attachments/assets/1c6e1aa6-db06-4c61-9493-92458496b67d)
 
- 6억 8천만개 데이터에 대한 메타데이터는 총 0.68TB

# 2단계: 개략적 설계안 제시 및 동의 구하기

## 객체 저장소의 속성

- 객체 불변성
    - 한번 저장된 객체는 변경은 불가능함.
    - 새 버전 객체로 대체는 가능
- key-value 저장소
    - 객체의 URI가 key고 데이터가 value가 됨
- write는 한 번, read는 여러 번
- 다양한 크기의 객체를 동시에 지원하는데 문제가 없음

## 객체 저장소의 설계 철학

- 파일의 식별자와 실제 데이터를 분리해서 저장
    - 메타데이터 저장소에 식별자를 저장하고, 데이터 저장소에 데이터를 저장한다
- 데이터는 불변이고, 메타데이터(식별자)는 변경 가능하다

![image](https://github.com/user-attachments/assets/dd00b38f-ce44-40da-be3e-1f83ad9e29da)


## 개략적 설계안

![image](https://github.com/user-attachments/assets/98638eef-8eec-4663-bacd-0f99688aeb76)

- API 서비스
    - IAM, 메타데이터 서비스, 저장소 서비스에 대한 호출을 조율하는 역할
    - stateless 서버 → 수평 확장 가능
- IAM 서비스
    - 인증/인가, 접근 제어를 담당

### 객체 업로드

![image](https://github.com/user-attachments/assets/8cc4359d-4e66-4e4a-8c3f-f563f6809455)

### 객체 다운로드

![image](https://github.com/user-attachments/assets/9a12055e-a5aa-476a-8913-ca0a8c0f0114)

# **3단계: 상세 설계**

## 1. 데이터 저장소

### 데이터 저장소의 구조

![image](https://github.com/user-attachments/assets/94e54295-cf49-4020-8121-c227ad91b572)

- 데이터 라우팅 서비스
    - 데이터 노드에 접근하기 위한 RESTful or gRPC 서비스를 제공
    - 배치 서비스를 호출해서 데이터를 어떤 노드에 저장할지 판단
    - 데이터 노드에서 데이터를 읽어와서 API 서비스에 반환
    - 데이터 노드에 데이터 기록
- 배치 서비스
    - 어느 데이터 노드에 데이터를 저장할지 결정하는 역할
        - 데이터 노드가 추가되거나 삭제되는 상황에서도 선정되는 데이터 노드가 최대한 유지되도록 하기 위해서 consistent hash를 주로 사용
    - 내부에 가상 클러스터 지도를 유지하고, 이 지도를 사용해서 데이터 사본이 물리적으로 서로 다른 위치에 저장되도록 함
    - 모든 데이터 노드와 하트비트 메시지를 주고받으면서 데이터 노드의 상태를 모니터링 함
    - 5~7개의 노드를 갖는 배치 서비스 클러스터를 Paxos나 Raft 같은 합의 프로토콜을 사용하여 구축하는 것을 권장
        - 건강한 노드 수가 절반 이상이면 서비스 지속 가능
- 데이터 저장 흐름
    
![image](https://github.com/user-attachments/assets/7fae721e-63df-45e9-adcb-039a9a3e93be)

    *※ 모든 secondary 노드에 데이터 저장이 완료된 이후에 응답을 반환*
    

### 데이터 저장 방식

- 방법1: 각 객체를 개별 파일로 저장
    - 작은 파일이 많은 경우 성능이 떨어지기 때문에 기각
        
        이유) 디스크 블록보다 작은 파일을 저장할 때도 무조건 1개의 디스크 블록이 사용되므로 디스크 블록이 낭비되고, 파일 수가 과도하게 많아지면 아이노드가 고갈될 위험이 있음
        
- 방법2: 작은 객체를 하나의 큰 파일로 모아서 저장
    - 객체를 저장할 때는 이미 존재하는 파일에 추가하는 방식으로 저장
    - 파일이 용량 임계치에 도달하면 읽기 전용으로 바꾸고 새 파일에 저장 시작

### 객체 소재 확인

- 하나의 파일 안에 여러 객체가 저장되어 있기 때문에 객체가 보관된 파일, 파일 내 객체의 오프셋, 객체 크기를 알아야 객체를 찾을 수 있다
- 이 데이터는 한번 저장되면 변경되지 않고 쓰기보다 읽기가 빈번하기 때문에 읽기 성능이 좋은 RDBMS에 저장한다
- 또한 데이터 노드끼리 공유할 필요가 없는 데이터이므로 각 데이터 노드마다 각자의 DB를 가지고, 거기에 저장해도 됨

### 데이터 노드 안에서의 데이터 저장 흐름

![image](https://github.com/user-attachments/assets/e8f68a0a-128a-4259-a469-95f8d97b7de9)

### 데이터 내구성

목표 수준은 99.9999%

- replication
    - 회전식 드라이브의 연간 장애율이 0.81%라고 하면, 3중 복제를 할 경우 $1 - 0.0081^3$ =~ 0.999999로 목표 수준에 근접
    - 이때 장애 도메인을 고려해서 복제 드라이브를 배치해야 한다
        - 여러 AZ에 복제해두면 장애 여파를 최소화할 수 있음
- erasure coding(소거 코드)
    - 데이터를 작은 단위로 나누어서 다른 서버에 분할해서 저장
    - 데이터 복구에 필요한 parity를 미리 만들어두고, 데이터 일부가 소실되었을 경우 이걸 사용해서 전체 데이터를 복구
- replication과 erasure coding 장단점 비교
    
![image](https://github.com/user-attachments/assets/40073bf4-298d-4c0e-94e0-186236249e1d)


### 데이터 정확성 검증

- 체크섬을 사용
- 객체 데이터 끝에 체크섬을 추가 저장

  ![image](https://github.com/user-attachments/assets/0070e3b4-ecb6-4f6c-85f3-c8eb09490ed5)

- 데이터를 읽을 때 데이터와 체크섬을 모두 읽어와서 데이터에 대한 체크섬을 계산하고 이 값이 가져온 체크섬과 일치하는지 확인

## 2. 메타데이터 데이터 모델

### 요구사항

- 메타데이터를 저장할 DB는 다음 3가지 질의를 지원해야 함
    1. 객체 이름으로 객체 ID 찾기
    2. 객체 이름에 기반하여 객체 삽입 또는 삭제
    3. 같은 접두어를 갖는 버킷 내의 모든 객체 목록 확인

### object 테이블의 규모 확장

- 데이터 양이 많으므로 샤딩이 필요
- 샤딩키 선정
    1. bucket_name
        1. 같은 버킷에 속하는 객체는 같은 샤드에 저장되도록 유도하기
        2. 한 버킷 안에 수십억 개의 객체가 있는 케이스를 지원하지 못하므로 탈락
    2. object_id
        1. 균등하게 분산되어 저장된다는 장점이 있음
        2. 하지만, 읽기 질의는 URI로 들어오고 URI에는 bucket_name이 포함되어 있기 때문에 읽기 질의를 효율적으로 지원하지 못해서 탈락
    3. bucket_name + object_name 
        1. URI로 들어오는 읽기 질의를 효율적으로 처리할 수 있음

## 3. 버킷 내 객체 목록 확인 기능

- 객체 저장소는 데이터를 수평적으로 저장하지만, 계층적 구조의 느낌을 주기 위해 **접두어**라는 개념을 지원
- AWS S3가 지원하는 목록 출력 명령어는 다음과 같이 사용됨
    1. 어떤 사용자가 가진 모든 버킷 목록 출력
    2. 주어진 접두어를 가진 같은 버킷 내 모든 객체 목록 출력
    3. 주어진 접두어를 가진 같은 버킷 내 모든 객체를 재귀적으로 출력
    - 2와 3의 차이점
        
        다음과 같은 객체가 있을때
        
        > CA/cities/losangeles.txt
        CA/cities/sanfrancisco.txt
        > 
        
        ‘CA’를 접두어로 두고 2와 3을 질의하면
        
        2번의 결과는 CA/ 이고,
        
        3번의 결과는 CA/cities/losangeles.txt, CA/cities/sanfrancisco.txt 이다.
        

### 단일 데이터베이스
- 모든 버킷 목록 출력을 위한 쿼리

- 같은 접두어를 가진, 같은 버킷 내 모든 객체 목록 출력을 위한 쿼리  
    - 2번 케이스를 위해 객체들을 디렉토리처럼 보이도록 묶는 작업은 애플리케이션이 담당

### 분산 데이터베이스

- 검색 질의를 모든 샤드에 보낸 다음 결과를 취합
- 페이징을 구현하기 복잡함
    - 각 샤드에 몇 개의 객체가 있는지 모르기 때문에 모든 샤드의 오프셋을 각각 추적해야 함
    - 버킷 ID로 샤딩하는 별도의 테이블에 목록 데이터를 비정규화하는 방법 사용 가능
        - 하지만, 객체 목록 출력 명령의 성능은 우선순위가 높지 않다. 따라서 굳이 안해도 됨

## 4. 객체 버전

- 한 객체에 여러 버전을 두는 기능
- 메타데이터 저장소의 object 테이블에 object_version 이라는 필드를 추가
- 데이터 저장할 때 <bueckt_id, object_name> 은 같지만 <object_id, object_version>은 새로운 값인 레코드를 메타데이터 저장소에 추가
    
![image](https://github.com/user-attachments/assets/347b61dc-2d26-402c-bd11-0d083a9713de)

- object_version은 새로운 레코드가 테이블에 추가될 때 만들어지는 TIMEUUID → TIMEUUID가 가장 큰 값이 가장 최신의 버전
- 삭제할 때도 새로운 버전의 레코드를 추가. 단 delete marker로 삭제되었음을 표시
    
![image](https://github.com/user-attachments/assets/00074417-26ab-43da-91ec-5c8da750cb8e)


## 5. 큰 파일의 업로드 최적화

- 큰 파일을 한번에 올리다가 네트워크 이슈 등으로 실패하면 다시 처음부터 올려야 함
- 큰 객체를 쪼개서 독립적으로 업로드하는 멀티파트 업로드를 사용
- 멀티파트 업로드 동작 방법
    - 각 파트가 업로드될때마다 해당 파트에 대한 ETag를 생성해서 클라이언트에 전달
    - 모든 파트가 업로드되고 나면 클라이언트는 파트목록과 ETag목록을 포함해서 멀티파트 업로드 종료 요청을 보냄
    - 데이터 저장소는 파트 목록을 사용해서 원본 객체를 복원한다
- 파일 업로드가 완료되면 파트들은 필요가 없기 때문에 삭제해야 함

## 6. Garbage Collection

불필요한 데이터를 삭제해서 용량 확보를 해야 함

![image](https://github.com/user-attachments/assets/eef0f7cf-78d8-4431-bc49-f063a0215251)

- object_id와 object_size는 변하지 않고, file_name과 offset은 변경된다
